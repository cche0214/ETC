# 07_数据治理标准 (Data Governance)

## 1. 原始数据概况
数据源包含 8 个主要字段，存在大量脏数据（如缺失值、格式不统一）。
*   **来源**：2023年12月 - 2024年1月的高速过车记录。

## 2. 字段定义与清洗规则

| 索引 | 字段名 | 含义 | 清洗/处理规则 |
| :--- | :--- | :--- | :--- |
| 0 | `GCXH` | 过车序号 | 唯一 ID，通常以 'F' 开头，保留。 |
| 1 | `XZQHMC` | 行政区划 | 包含：睢宁县, 邳州市, 丰县, 高速五大队, 沛县, 铜山县, 新沂市。 |
| 2 | `ROAD_ID` | 道路编号 | 如 G3, G2513。 |
| 3 | `K_INDEX` | 桩号(K值) | 表示距离起点的公里数，如 K731。 |
| 4 | `BOUNDARY_LEVEL` | 边界级别 | `PROVINCE` (省界), `CITY` (市界)。 |
| 5 | `BOUNDARY_DETAIL` | 边界详情 | 如 "江苏-山东"。 |
| 6 | `BOUNDARY_LABEL` | 边界标签 | 如 "苏鲁界"。 |
| 7 | `CLEAN_KKMC` | 清洗卡口名 | **核心字段**。生成规则：`{ROAD_ID}-{K_INDEX}-{级别描述}` (如 G3-K731-省际卡口)。 |
| 8 | `FXLX` | 方向类型 | 1 或 2。清洗发现取值为 2 的通常特定于睢宁县。 |
| 9 | `GCSJ` | 过车时间 | 格式 `yyyy-MM-dd HH:mm:ss`。 |
| 10 | `GCSJ_TS` | 时间戳 | **关键修正**：原始数据为北京时间，转换为 Unix Timestamp 时需注意时区。修正逻辑：`Beijing_Time - 8h = UTC` -> Timestamp。 |
| 11 | `HPZL` | 号牌种类 | 代码 (01, 02...)。 |
| 12 | `HPZL_LABEL` | 号牌标签 | 映射值：01-大型汽车, 02-小型汽车, 52-教练车 等。 |
| 13 | `HPHM` | 号牌号码 | 格式清洗：正则校验 `^[京津...]...`，去除非法字符。 |
| 14 | `BRAND` | 车辆品牌 | 从原始 `CLPPXH` 字段提取，去除车型和年款信息。 |

## 3. 时间戳陷阱与修正
*   **问题**：原始 CSV 时间字符串 (如 `00:00:01`) 是 **北京时间 (CST)**。如果在转换时被误当作 **UTC** 处理，会导致生成的时间戳多出 8 小时（28800秒）。
*   **解决**：在清洗脚本或 Flink 处理中，明确指定时区为 `Asia/Shanghai` 或手动减去 8 小时偏移量，确保 `GCSJ_TS` 是标准的 Unix Timestamp (UTC)。

## 4. 存储规范
*   **HBase**: 全字段存储，RowKey 包含时间倒序。
*   **MySQL**: 同样存储全字段，主要用于多维分析。
*   **Redis**: 仅存储聚合后的统计值或报警摘要，Key 命名遵循 `Project:Module:Type:ID` 规范。

