# 01_项目概览与演进 (Project Overview & Evolution)

## 1. 项目简介
本项目是一个基于 Hadoop, Spark, Flink 和 HBase 等大数据技术栈构建的高速公路 ETC (Electronic Toll Collection) 大数据管理与监控系统。
系统旨在处理海量的高速公路过车记录数据，实现数据的实时采集、清洗、存储、实时分析（如套牌车检测、流量统计）以及交互式查询与可视化展示。

## 2. 核心目标
项目主要围绕以下核心需求展开：
1.  **数据治理与存储**：处理原始脏数据，清洗标准化，并构建高效的存储架构（HBase + 分库分表的 MySQL）。
2.  **实时流计算**：利用 Flink 对 Kafka 接入的实时数据进行处理，实现毫秒级的套牌车检测和分钟级的路段流量统计。
3.  **交互式智能查询**：基于 LangChain 和 LLM (DeepSeek) 构建 SQL Agent，允许用户通过自然语言查询交通数据。
4.  **可视化大屏**：实时展示路网流量、跨省/市流动情况及异常报警信息。

## 3. 技术架构栈

| 层次 | 技术组件 | 说明 |
| :--- | :--- | :--- |
| **数据源** | CSV Files | 原始过车记录数据 (2023.12 - 2024.01) |
| **消息队列** | Kafka 2.4.1 | 实时数据接入，Topic: `etc_traffic_data` |
| **流计算** | Flink 1.10.0 (Java) | 实时清洗、套牌车检测、流量聚合 (`StreamAnalysisJobV2`) |
| **存储层 - 宽表** | HBase 2.3.6 | 存储海量全量明细数据，RowKey 优化支持时序查询 |
| **存储层 - 统计** | Redis 6.2.6 | 存储实时热点数据（如套牌报警列表、实时流量桶） |
| **存储层 - 关系** | MySQL 5.7.41 | 存储清洗后的结构化数据，用于复杂 SQL 查询和 Agent 交互 |
| **中间件** | ShardingSphere-Proxy | 实现 MySQL 的分库分表路由 (3库 x 4表) |
| **后端服务** | FastAPI / Flask | 提供 REST API，集成 LangChain Agent 服务 |
| **AI/Agent** | LangChain + DeepSeek | Text-to-SQL 智能问答 |
| **前端可视化** | Vue.js + ECharts | 数据大屏展示与交互界面 |
| **基础设施** | Ubuntu 22.04 (Cluster) | CloudLab 三节点集群 (node1, node2, node3) |

## 4. 关键特性
*   **双模计算架构**：
    *   **流式 (Streaming)**：Kafka -> Flink -> HBase/Redis (实时监控)
    *   **批/交互式 (Batch/Interactive)**：MySQL (分片) -> LLM Agent (历史分析)
*   **智能运维**：
    *   **高并发模拟**：通过 Python 脚本 (`windows_csv_producer.py`) 模拟每秒 50+ 条的实时数据流。
    *   **RAG 知识库**：集成 RAG 提供项目文档与运维知识的智能问答。

## 5. 项目演进时间线 (Dev Log)

### 第一阶段：基础设施与探索 (2025.11.30 - 12.04)
*   **11.30 - 项目规划**：
    *   确定初步技术路线：Kafka -> Flink -> HBase。
    *   搭建三节点虚拟机集群 (node1, node2, node3)，配置 Hadoop/HBase 环境。
    *   遇到原始数据“脏、乱、差”的问题，着手设计清洗规则。
*   **12.02 - 数据治理**：
    *   深入分析 2023.12.01 数据，确定 8 大核心字段。
    *   解析业务逻辑：方向字段(FXLX)与行政区划的关联，车牌号的正则脱敏规则。
    *   制定 `ROAD_ID` + `K_INDEX` 映射 `CLEAN_KKMC` (唯一卡口名) 的核心逻辑。
*   **12.03 - 架构调整**：
    *   确定“批流分离”思想：流处理负责 HBase 存储和实时报警，交互式查询走 MySQL。
    *   尝试本地运行 Flink，但遭遇版本兼容性地狱 (Flink 1.10 vs HBase 2.x)。

### 第二阶段：核心链路打通 (2025.12.05 - 12.08)
*   **12.05 - 链路贯通**：
    *   成功实现 Kafka -> Flink -> HBase 的数据通路。
    *   掌握了 HBase 的 `truncate` 重置操作和 Kafka 消费者组管理，建立了一套标准的测试清洗流程。
*   **12.06 - 实时计算增强**：
    *   引入 **Redis** 作为实时缓存数据库。
    *   攻克 **套牌车检测** 难点：利用 Flink 的 `KeyedState` 存储每辆车的 [地点, 时间]，计算时空距离。
    *   **重大修正**：发现 Unix 时间戳转换的时区 Bug (误将 CST 当作 UTC)，修正了 8 小时偏差。
*   **12.08 - 中间件升级**：
    *   放弃配置繁琐且不稳定的 MyCat。
    *   采用 **ShardingSphere-Proxy** (端口 3307) 接管 MySQL 分库分表，极大简化了逻辑库配置。

### 第三阶段：智能化与收尾 (2025.12.14 - 12.20)
*   **12.14 - 流量预测**：
    *   基于 Redis 的滑动窗口数据 (9个时间步)，利用 LSTM 模型尝试进行流量预测。
*   **12.15 - 预测调试**：
    *   修复模型文件路径错误，跑通预测流程。
*   **12.20 - 最终架构定型**：
    *   确立 **3库12表** 的 MySQL 分片策略 (按行政区划垂直拆分库，按车牌哈希水平拆分表)。
    *   前端 Vue 接入 LangChain Agent，实现“自然语言 -> SQL -> 图表”的完整交互闭环。
    *   项目进入文档整理与 RAG 知识库构建阶段。

